# ğŸ§  ai-agent

Agente IA razonador construido con **LangChain** + **OpenAI** (GPT-4).\
Orquesta tareas complejas de DevOps mediante razonamiento LLM y llamada modular a herramientas IA propias del ecosistema `devops-ai-lab`.

---

## ğŸ¯ PropÃ³sito

Centraliza la lÃ³gica de decisiÃ³n y automatizaciÃ³n DevOps basada en LLMs, encapsulando como **tools** los microservicios IA accesibles vÃ­a `ai-gateway`.\
Permite analizar logs, validar charts Helm y generar Jenkinsfiles de forma unificada, aÃ±adiendo trazabilidad y observabilidad avanzada (MCP).

Este agente es la entrada cognitiva real de la arquitectura.

---

## ğŸ”§ Funcionalidad

El agente expone varias **tools** que actÃºan como wrappers HTTP a microservicios IA desplegados en Kubernetes:

| Tool                | Endpoint Gateway     | DescripciÃ³n                                                        |
| ------------------- | -------------------- | ------------------------------------------------------------------ |
| `generate_pipeline` | `/generate-pipeline` | Genera Jenkinsfile a partir de una descripciÃ³n en lenguaje natural |
| `analyze_log`       | `/analyze-log`       | DiagnÃ³stico y soluciÃ³n de logs Jenkins/CI vÃ­a LLM                  |
| `lint_chart`        | `/lint-chart`        | Linting semÃ¡ntico de Helm Charts comprimidos (.tgz)                |

Todas las tools inyectan el campo `caller: ai-agent-langchain` en el payload para trazabilidad.

---

## âš™ï¸ Estructura del Proyecto

```
ai-agent/
â”œâ”€â”€ main.py                         # Entry point: ejecuta el agente LangChain y orquesta las tools
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ai_gateway_tools.py         # DefiniciÃ³n y lÃ³gica HTTP de cada tool
â”œâ”€â”€ clients/
â”‚   â””â”€â”€ gateway_client.py           # (opcional, para lÃ³gica extendida de cliente HTTP)
â”œâ”€â”€ chart_example/
â”‚   â””â”€â”€ helm-log-analyzer-0.1.5.tgz # Chart de ejemplo para pruebas de linting
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ examples.md
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ Dockerfile
```

---

## ğŸš€ EjecuciÃ³n Local

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python main.py
```

Puedes interactuar con el agente vÃ­a CLI, o modificar el main para ejecutar pruebas directas sobre las tools.

---

## ğŸŒ ComunicaciÃ³n con el entorno

El agente se comunica con `ai-gateway` mediante peticiones HTTP internas (Kubernetes service).\
Endpoints activos:

- `POST /generate-pipeline`
- `POST /analyze-log`
- `POST /lint-chart`

Todos los prompts, respuestas y eventos son registrados por el gateway en disco y auditados vÃ­a mensajes MCP.

---

## ğŸ§  Inteligencia y Modelos

- **Modelo por defecto:** OpenAI GPT-4 (puedes adaptar a Mistral/Ollama modificando la config y el microservicio backend).
- Todas las llamadas tools fijan el motor a `ollama` por defecto, pero es configurable.
- Futuro: integraciÃ³n de modelo fine-tuneado propio (`flan-t5` u otros).

---

## ğŸ” Observabilidad y Trazabilidad

- **Logs** detallados en cada paso (inicio, input, resultado, error) en stdout (visible en pods Kubernetes).
- **MCP**: Cada ejecuciÃ³n relevante es registrada por `ai-gateway` mediante mensajes MCP, incluyendo metadata (caller, paths, microservicio, etc).

---

## ğŸ“¦ Dependencias principales

```text
langchain
openai
aiohttp
pydantic
python-dotenv
```

---

## ğŸ“Œ Estado actual

-

---

## ğŸ‘¨â€ğŸ’» Autor

**Dani**\
[github.com/dorado-ai-devops](https://github.com/dorado-ai-devops)

---

## ğŸ›¡ Licencia

Licencia PÃºblica General GNU v3.0

