
# ğŸ§  ai-agent

Agente IA razonador construido con **LangChain** + **OpenAI** (GPT-4).  
Orquesta tareas complejas de DevOps mediante razonamiento LLM y llamada modular a herramientas IA propias del ecosistema `devops-ai-lab`.

---

## ğŸ¯ PropÃ³sito

Centraliza la lÃ³gica de decisiÃ³n y automatizaciÃ³n DevOps basada en LLMs, encapsulando como **tools** los microservicios IA desplegados vÃ­a `ai-gateway`.  
Permite analizar logs, validar charts Helm, generar Jenkinsfiles y recuperar contexto desde una base vectorial documentacional.  
Este agente es la **entrada cognitiva real de la arquitectura**.

---

## ğŸ”§ Funcionalidad

El agente expone varias **tools** conectadas a servicios internos o externos:

| Tool                    | FunciÃ³n                                                                 |
|-------------------------|-------------------------------------------------------------------------|
| `generate_pipeline`     | Genera Jenkinsfile desde texto natural vÃ­a `ai-pipeline-gen`            |
| `analyze_log`           | DiagnÃ³stico inteligente de logs CI/CD con `ai-log-analyzer`             |
| `lint_chart`            | Linting semÃ¡ntico de Helm Charts comprimidos (.tgz)                     |
| `analyze_helm_chart`    | Clona, empaqueta y analiza un Helm Chart desde GitHub automÃ¡ticamente   |
| `list_github_repos`     | Lista todos los repos pÃºblicos de `dorado-ai-devops`                    |
| `query_vector_db`       | Recupera contexto semÃ¡ntico desde `ai-vector-db` usando bÃºsqueda LLM    |

Todas las tools inyectan `caller: ai-agent-langchain` para trazabilidad MCP.

---

## âš™ï¸ Estructura del Proyecto

```
ai-agent/
â”œâ”€â”€ main.py                         # Punto de entrada del agente (FastAPI)
â”œâ”€â”€ tools/                          # Tools expuestas al agente
â”‚   â”œâ”€â”€ ai_gateway_tools.py         # Wrappers HTTP a los microservicios
â”‚   â”œâ”€â”€ github_tools.py             # Listado de repositorios desde GitHub
â”‚   â”œâ”€â”€ helm_chart_tools.py         # Fetch + lint automÃ¡tico de Helm Charts
â”‚   â””â”€â”€ vector_db_tools.py          # Consulta semÃ¡ntica al vector DB
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ examples.md                 # Ejemplos y frases de prueba
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py                 # ConfiguraciÃ³n general
â”œâ”€â”€ chart_example/
â”‚   â””â”€â”€ helm-log-analyzer-0.1.5.tgz
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸŒ API REST

El agente corre en un servidor FastAPI con el endpoint:

- `POST /ask`  
  Payload: `{"prompt": "tu pregunta en lenguaje natural"}`  
  Devuelve: `{"result": "respuesta generada (tool o razonamiento)"}`

El agente identifica si necesita contexto, ejecuta tools, y resume resultados.

---

## ğŸ“š Contexto SemÃ¡ntico (Vector DB)

`query_vector_db` permite que el agente acceda a contexto tÃ©cnico/documental recuperado semÃ¡nticamente desde la base vectorial `ai-vector-db`, la cual indexa documentaciÃ³n de todos los microservicios del ecosistema `devops-ai-lab`.

El agente puede consultar conceptos como:

```
Â¿QuÃ© hace ai-chat-ui?
Â¿DÃ³nde estÃ¡ implementado el fetch de charts?
```

Y usarÃ¡ la respuesta como contexto antes de contestar.

---

## ğŸ§  Inteligencia y Modelos

- **Modelo por defecto:** OpenAI GPT-4 (via `langchain_openai.ChatOpenAI`)
- **Motor IA de los tools:** configurable (`ollama`, `openai`) segÃºn `AI_VENDOR`

---

## ğŸš€ EjecuciÃ³n Local

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python main.py
```

AsegÃºrate de tener acceso al `ai-gateway`, y de definir las variables de entorno necesarias (`GH_SECRET`, `AI_VENDOR`, etc.).

---

## ğŸ” Observabilidad y Trazabilidad

- **Logs** en consola para cada tool: inicio, input, resultado, error.
- **MCP (Message Control Plane)**: mensajes emitidos desde `ai-gateway` con trazabilidad por caller, microservicio y peticiÃ³n.

---

## ğŸ“¦ Dependencias principales

```text
langchain
langchain-openai
aiohttp
fastapi
openai
requests
uvicorn
pydantic
python-dotenv
```

> AÃ±ade `ollama-client` si invocas Ollama localmente.

---

## ğŸ“Œ Estado actual

âœ… Funcional  
ğŸ§ª En constante expansiÃ³n (vector-db, fine-tuning, validaciÃ³n avanzada)

---

## ğŸ‘¨â€ğŸ’» Autor

**Dani**  
[github.com/dorado-ai-devops](https://github.com/dorado-ai-devops)

---

## ğŸ›¡ Licencia

Licencia PÃºblica General GNU v3.0
